# Build-Your-Own-LLM

## Purpose
Most of the LLM foundation models, even if they are called Open, are behind closed doors controlled by the Big Tech. The research community is doing an amazing job to democratize LLMs, with the limited resources at their disposal. This repo is intended to capture the guidance and resources that allow you to build and fine-tune LLMs based on open source.

Please create a pull request if you have something helpful to share.

### Open Source LLMs
+ [List of Open Sourced Fine-Tuned LLMs](https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76)
#### Foundation (Base) LLMs
+ [LLaMa from Facebook](https://github.com/facebookresearch/llama) This model has been [leaked](https://www.deeplearning.ai/the-batch/how-metas-llama-nlp-model-leaked/) and can be found on torrents.

#### Instruction Tuned LLMs
+ Alpaco
+ Koala
+ HuggingFace

### Frameworks to interact with and use LLMs
[LangChain - Building applications with LLMs through composability](https://github.com/hwchase17/langchain)
[LlamaIndex - Connect your LLM's with external data](https://github.com/jerryjliu/llama_index)

### Run LLM on your Laptop (low resource devices)
[Run the LLaMA model using 4-bit integer quantization on a MacBook](https://github.com/ggerganov/llama.cpp)

### Datasets to train your LLM (if you have the infra)
[Common Crawl](https://commoncrawl.org/)
